% Chapter21 Online Learning, Understanding Machine Learning

\section{Online Learning}%
\label{sec:online_learning}

\subsection{ONLINE CLASSIFICATION IN THE REALIZABLE CASE}%
\label{sub:online_classification_in_the_realizable_case}

Online learning is performed in a sequence of consecutive rounds, such as at round t:
\begin{itemize}
    \item get an instance $ \vec{x}_t $;
    \item predict the instance's label is $ \hat{y}_t $;
    \item get the correct label $ y_t $;
    \item update the mistakes count.
\end{itemize}

In the online learning model we make no statistical assumptions regarding the origin of the sequence of examples.
It can be deterministic, stochatic, or even adversarially adaptive to the learner's own behavior. If the adversary is arbitrary, the problem is meaningless.So in this section, we require the realizability assumption.

Realizability assumption: the labels are generated by some hypothesis, $ h^*: \mathcal{X} \rightarrow \mathcal{Y} $. And $ h^* $ is in our hyperthesis class $ \mathcal{H} $.

\begin{definition}
    \textbf{(Mistake Bounds, Online Learnability).}\\
    \[
        \forall S_T = ((x_1, h^*(x_1)), \ldots, (x_T, h^*(x_T))),
        M_A(S_T) =  \sum^{T}_{i=1} 1_{[A(S_{i-1})(x_i) \ne h^*(x_i)]} 
    \]
    \[
        M_{A}(\mathcal{H}) = \sup_{S_T \in (\mathcal{X}, \mathcal{Y})\times \cdots \times (\mathcal{X}, \mathcal{Y})} M_A(S_{T})
    \]
\end{definition}

In online learning, the goal is to study which hypothesis classes are learnable in the online model.

In ERM rule with realizability assumption, we want $ L_{\mathcal{D}}(h_{ERM}(S)) = 0 $. Analoguely, we want all rest hypothesises are consistent with all past examples. So, the \textbf{Consistent algorithm} maintains a set $ V_t $, of all the hypothesises which are consistent with $ ((x_1, y_1), \ldots, (x_{t-1}, y_{t-1})) $, which is called the version space.

\begin{corollary}
    Let $\mathcal{H}$ be a finite hypothesis class, $M_{Consistent}(\mathcal{H}) \le \left| \mathcal{H} \right| - 1$.
\end{corollary}

\begin{definition}
    \textbf{(Halving Algorithm).}\\
    Receive $ x_t $,
    $ \hat{y_t} = \arg\max_{y \in \left\{ 0, 1 \right\}} \left| \left\{ h \in V_t: h(x_t) = y \right\} \right| $.
    Then update $ V_{t+1} = \left\{ h \in V_t: h(x_t) = y_t\right\} $.
\end{definition}

\begin{corollary}
    Let $ \mathcal{H} $ be a finite hypothesis class, $ M_{Halving}(\mathcal{H}) \le \log_{2} (\left| \mathcal{H} \right|) $.
    \begin{proof}
        $ 1 \le \left| V_{T+1} \right| \le \left| \mathcal{H} \right| 2^{-M}$.
    \end{proof}
\end{corollary}

In PAC, any ERM hypothesis is good, but in online learning choosing an arbitrary ERM hypothesis is far from being optimal.

\subsubsection{Online Learnability}%

What's the optimal online learning algorithm for a given hypothesis class $ \mathcal{H} $?

A strategy for an adversarial environment can be formally described as a binary tree. A node i is a sample $ x_i $, the left edge means $ y_i = h^*(x_i) = 1 $, and the right edge means $ y_i = y^*(x_i) = 0 $. 

If the predictor give $ \hat{y_{i}} = 1 $, the adversary traverses to the right child, which means $ y_i = 0 $, otherwise traverses to the left child.

If we code node by line order, then $ i_1 = 1 $, $ i_{t+1} = 2i_{t} + y_t = 2^{t-1} + \sum^{t-1}_{j=1} y_j 2^{t - 1 - j} $.

\begin{definition}
    \textbf{($\mathcal{H}$ Shattered Tree).}
    A shattered tree of depth $ d $ is a sequence of instance $ v_1, \ldots, v_{2^d -1} $ in $ \mathcal{X} $ such that for every labeling $ (y_1, \ldots, y_d) \in {\left\{ 0, 1 \right\}}^d $, there exists $ h \in \mathcal{H} $ such that for all $ t \in [d] $ we have $ h(v_{i_t}) = y_t $ where $ i_t = 2^{t-1} + \sum^{t-1}_{j=1} y_j 2^{t - 1 - j} $.
\end{definition}

\begin{definition}
    \textbf{(Littlestrone's Dimension (Ldim)).}
    $ Ldim(\mathcal{H}) $ is the maximal integer T such that there exists a shattered tree of depth $ T $, which is shattered by $ \mathcal{H} $.
\end{definition}

\begin{lemma}
    \[
        \forall A, M_A(\mathcal{H}) \ge Ldim(\mathcal{H}).
    \]
\end{lemma}

\begin{definition}
    \textbf{(Standard Optimal Algorithm (SOA)).}
    \[
       \hat{y_t} = \arg\max_{y \in \left\{ 0, 1 \right\}} Ldim( \left\{ h \in V_t: h(x_t) = y \right\} )   
    \]
\end{definition}

\begin{lemma}
    \[
        M_{SOA}(\mathcal{H}) \le Ldim(\mathcal{H}).
    \]
    \begin{proof}
        We want to get $ Ldim(V_{t+1}) \le Ldim(V_{t}) - 1 $.
        Because $ Ldim(V_{t+1}) \le Ldim(V_t - V_{t+1}) $, then we can construct $ Ldim(V_{t+1})+1 $ deepth tree for class $ V_t $, which is shattered by $ V_t $. Therefore, $ Ldim(V_{t+1}) \le Ldim(V_t) - 1 $
    \end{proof}
\end{lemma}

\begin{theorem}
    \[
        \forall \mathcal{H}, VCdim(\mathcal{H}) \le Ldim(\mathcal{H}).
    \]
\end{theorem}
note: $ \exists \mathcal{H}, VCdim(\mathcal{H}) = 1, Ldim(\mathcal{H}) = \infty $.

\subsection{ONLINE CLASSFICATION IN THE UNREALIZABLE CASE}%
\label{sub:online_classfication_in_the_unrealizable_case}

\begin{definition}
    \textbf{(Regret).}
    \[
        Regret_{A}(h, T) = \sup_{S_T \in (\mathcal{X}, \mathcal{Y})\times\cdots\times(\mathcal{X}, \mathcal{Y})}
        \left[ \sum^{T}_{t=1} \left| \hat{y_t} - y_t \right| - \sum^{T}_{t = 1} \left| h(x_t) - y_t \right| \right]
    \]
    \[
        Regret_{A}(\mathcal{H}, T) = \sup_{S_T \in (\mathcal{X}, \mathcal{Y})\times\cdots\times(\mathcal{X}, \mathcal{Y})}
        \left[ \sum^{T}_{t=1} \left| \hat{y_t} - y_t \right| - \inf_{h \in \mathcal{H}}\sum^{T}_{t = 1} \left| h(x_t) - y_t \right| \right]
        = \sup_{h\in\mathcal{H}} Regret_{A}(h, T).
    \]
\end{definition}

We want $ Regret_{A}(\mathcal{H}, T) $ grows sublinearly with the number of rounds, $ T $, which implies that the difference between the error rate of the leaner and the best hypothesis in $ \mathcal{H} $ tends to zero as T goes to infinity.

In preceeding section's model, it is impossible. For $ \mathcal{H} = \left\{ h_0, h_1 \right\} $, where $ h_0 $ always returns 0, and $ h_1 $ is always return 1. Then the adversary can make the number of mistakes of any online algorithm be equal to T, but $ \inf_{h \in \mathcal{H}} \sum^{T}_{t=1} \left| h(x_t) - y_t \right| \le T/2$, which means that $ Regret_{A}(\mathcal{H}, T) \ge T/2 $.

So we need further restrict the power of the adversarial environment. We allow the learner to randomize his predictions, and the adversarial environment only know the probability distribution of the predictions, that is $ \mathbb{P}\left[ \hat{y_t} = 1 \right] = p_t $, then

\begin{align*}
    Regret_{A}(h, T) =& \sup_{S_T \in (\mathcal{X}, \mathcal{Y})\times\cdots\times(\mathcal{X}, \mathcal{Y})}
    \left[ \sum^{T}_{t=1} \mathbb{P} \{\left| \hat{y_t} - y_t \right|\} - \sum^{T}_{t = 1} \left| h(x_t) - y_t \right| \right]\\
    =& \sup_{S_T \in (\mathcal{X}, \mathcal{Y})\times\cdots\times(\mathcal{X}, \mathcal{Y})}
    \left[ \sum^{T}_{t=1} \{\left| p_t - y_t \right|\} - \sum^{T}_{t = 1} \left| h(x_t) - y_t \right| \right]
\end{align*}

\subsubsection{Weighted-Majority}%

\begin{algorithm}[H]
    \caption{Weighted-Majority}
    \begin{algorithmic}
        \Require{$ \mathcal{H} = \left\{ h_1, \ldots, h_d \right\} $; number of rounds T.}
        \Ensure{$ \hat w^{(1)} = (1, \ldots, 1), \eta = \sqrt{2\log(d)/T} $}
        \For{$ t = 1, 2, \ldots $}
        \State{$ Z_t = \sum^{d}_{i} \hat w ^{(t)}_{i}, w^{(t)} = \hat w ^{(t)}/Z_t $}
        \State{Choose hyperthesis $ h_i $ at random according to $ \mathbb{P}[h_i] = w^{(t)}_i $}
        \State{receive costs of all experts $ \vec{v}_t \in {[0,1]}^d $}
        \State{pay cost $ \langle \vec{w}^{(t)}, \vec{v}_t \rangle $}
        \State{$ \forall j, \hat{w}_j^{(t+1)} = \hat{w}^{t}_j e^{-\eta v_{t,j}} $}
        \EndFor.
    \end{algorithmic}
\end{algorithm}

Here is a abstract concept $ v_t $, which means the cost of each hyperthesis.Let the cost $ v_t \in {[0,1]}^d $.

\begin{theorem}
    Assuming that $ T > 2\log(d) $, the Weighted-Majority algorithm enjoys the bound
    \[
        \sum^{T}_{t=1} \langle w^{(t)}, v_t \rangle - \min_{i \in [d]} \sum^{T}_{t=1} v_{t,i} \le \sqrt{2\log(d) T}.
    \]
    \begin{proof}
        \[
            \log \frac{Z_{t+1}}{Z_t} = \log \sum^{d}_{i=1} \frac{\hat w ^{(t)}_i}{Z_t} e^{-\eta v_{t,i}} = \log \sum^{d}_{i} w^{(t)}_i e^{-\eta v_{t, i}}.
        \]
        For $ e^{-a} \le 1 - a + a^2/2 $,
        \begin{align*}
            \log \frac{Z_{t+1}}{Z_t} \le& \log \sum^{d}_{i=1} w^{(t)}_{i} \left( 1 - \eta v_{t, i} + \eta^2 v^2_{t,i}/2 \right)\\
            =& \log(1 - \sum^{d}_{i=1} w^{(t)}_i \left( \eta v_{t,i} - \eta^2 v^2_{t, i}/2 \right))\\
            \le& -\sum^{d}_{i=1} w^{(t)}_i \left( \eta v_{t,i} - \eta^2 v^2_{t, i}/2 \right)\\
            \le& -\eta \langle w^{(t)}, v_t \rangle + \eta^2/2\\
            \log(Z_{T+1}) - \log(Z_1) =& \sum^{T}_{t=1} \log \frac{Z_{t+1}}{Z_t} \le -\eta \sum^{T}_{t=1} \langle w^{(t)}, v_t \rangle + \frac{T \eta^2}{2} \\
            \log Z_{T+1} = \log \left( \sum^{d}_{i=1} e^{-\eta \sum^{T}_{t} v_{t, i} }\right) \ge& \log\left( \max_i e^{-\eta \sum^{T}_{t} v_{t, i}} \right) = -\eta\min_i \sum^{T}_{t} v_{t,i}\\
            -\eta\min_i \sum^{T}_{t} v_{t,i} - \log(d) \le& -\eta \sum^{T}_{t=1} \langle w^{(t)}, v_t \rangle + \frac{T \eta^2}{2} \\
            \sum^{T}_{t=1} \langle w^{(t)}, v_t \rangle - \min_i \sum^{T}_{t} v_{t,i} \le& \frac{\log(d)}{\eta} + \frac{\eta T}{2} \le \sqrt{2 \log(d) T}
        \end{align*}
    \end{proof}
\end{theorem}

\begin{theorem}
    \[
        \forall h \in \mathcal{H}, \Omega\left( \sqrt{Ldim(\mathcal{H})T} \right) \le Regret_{A}(h, T) \le \sqrt{2 \min \left\{ \log(\left| \mathcal{H} \right|), Ldim(\mathcal{H})\log(eT) \right\}T}.
    \]
\end{theorem}
\begin{proof}
    We begin with finite class $ \mathcal{H} = \left\{ h_1, \ldots, h_d \right\} $.
    The cost $ v_{t,i} = \left| h_i(x_t) - y_t \right| $. Let $ p_t = \sum^{d}_{i} w^{(t)}_{i} h_i (x_t) \in [0,1] $, and the loss is
    \[
        \left| p_t - y_t \right| = \left| \sum^{d}_{i=1} w^{(t)}_i h_i(x_t) - y_t \right| = \left| \sum^{d}_{i=1} (w^{(t)}_i (h_i(x_i)) - y_t) \right| =  \sum^{d}_{i=1}  w^{(t)}_i \left|h_i(x_t) - y_t \right| = \langle w^{(t)}, v_t \rangle
    \]
    \[
        Regret_A(\mathcal{H}, T) \le \sqrt{2 \log(\left| \mathcal{H} \right|)T}
    \]
\end{proof}

Let $ \mathcal{H} $ be any hypothesis class with $ Ldim(\mathcal{H}) < \infty $. $\forall \left\{ x_1, x_2, \ldots, x_T \right\} \in \mathcal{X} \times \cdots \times \mathcal{X} $. For any $ h \in \mathcal{H} $, $ \exists L \le Ldim(\mathcal{H}) $ and indices $ 1 \le i_1 < i_2 < \cdots < i_L \le T $ such that $ Expert(i_1, i_2, \ldots, i_L) $ predicts exactly $ h(x_t) $. $ i_L $ is the round that SOA algorithm prediction is different with $ h(x_t) $. (Seeing expert algorithm.)\\
The mistake sequences $ (i_1, i_2, \ldots, i_L) $'s num is
\[
    d = \sum^{Ldim(\mathcal{H})}_{L=0} \mathbb{C}^T_{L} \le {\left( \frac{eT}{Ldim(\mathcal{H})}  \right)}^{Ldim(\mathcal{H})} 
\]
These experts constructed from $ \mathcal{H} $ 


\subsection{ONLINE CONVEX OPTIMIZATION}%
\label{sub:online_convex_optimization}

Convex learning, $ \mathcal{H} $ is convex and $ \forall z \in Z, l(\cdot, z) $ is a convex function.

\[
    Regret_A(w, T) = \sum^{T}_{t=1} l(w^{(t)}, z_t) - \sum^{T}_{t=1} l(w, z_t).
\]

\[
    Regret_A(\mathcal{H}, T) = \sup_{w \in \mathcal{H}} Regret_A(w, T).
\]

\begin{definition}
    \textbf{(Online Gradient Descent).}
    \begin{enumerate}
        \item $ v_t \in \partial_{w} l(w^{(t)}, z_t) $
        \item $ w^{(t+1/2)} = w^{(t)} - \eta v_t $
        \item $ w^{(t+1)} = \arg\min_{w \in \mathcal{H}} \Arrowvert w - w^{(t+1/2)} \Arrowvert $
    \end{enumerate}
\end{definition}

\begin{theorem}
    \[
        \forall w \in \mathcal{H},\quad Regret_A(w, T) \le \frac{ \Arrowvert w \Arrowvert^2 }{ 2\eta } + \frac{\eta}{2} \sum^{T}_{t=1} \Arrowvert v_t \Arrowvert^2
    \]
    If $ \forall t, l(\cdot, z_t) $ is $ \rho $-Lipschitz, then setting $ \eta = 1/\sqrt{T} $ yields
    \[
        Regrets_A(w, T) \le \frac{1}{2} ( \Arrowvert w \Arrowvert^2 + \rho^2) \sqrt{T}
    \]
    If we futher assume that $ \mathcal{H} $ is B-bounded and we set $ \eta = \frac{B}{\rho \sqrt{T}}  $, then
    \[
        Regret_{A}(\mathcal{H},T) \le B\rho\sqrt{T}
    \]
    \begin{proof}
        \begin{align*}
            \Arrowvert w^{(t+1)} - w \Arrowvert^2 - \Arrowvert w^{(t)} - w \Arrowvert^2
            =& \Arrowvert w^{(t+1/2)} - w \Arrowvert^2 - \Arrowvert w^{(t)} - w \Arrowvert^2\\
            = -2\eta \langle w^{(t)} - w, v_t \rangle + \eta^2 \Arrowvert v_t \Arrowvert^2
            \le& -2\eta (l(w^{(t)}, z_t) - l(w, z_t)) + \eta^2 \Arrowvert v_t \Arrowvert^2\\
            \Arrowvert w^{(T+1)} - w \Arrowvert^2 - \Arrowvert w^{(1)} - w \Arrowvert^2
            \le& -2\eta \sum^{T}_{t=1} (l(w^{(t)}, z_t) - l(w, z_t)) + \eta^2 \sum^{T}_{t=1} \Arrowvert v_t \Arrowvert^2\\
            Regret_A(w, T) \le& \frac{\Arrowvert w \Arrowvert^2 }{2 \eta} + \frac{\eta}{2} \sum^{T}_{t=1} \Arrowvert v_t \Arrowvert^2
        \end{align*}
    \end{proof}
\end{theorem}

In previous proof, $ \eta $ is dependented on $ T $. We can use doubling trick to avoid this.
We let $ 2^M \le T < 2^{M+1} $. First, we have $ Regret_A(w, 2^m) \le \alpha \sqrt{2^m} $.
\begin{align*}
    Regret_A(w, T) \le \sum^{M+1}_{m=1} Regret_A(w, 2^m) \le \alpha \sum^{M+1}_{m=1} {(\sqrt 2)}^m \le \alpha \frac{{(\sqrt 2)}^{M+2} - \sqrt 2}{\sqrt 2 - 1}  < \frac{2}{\sqrt 2 - 1} \alpha \sqrt T.
\end{align*}


\subsection{THE ONLINE PERCEPTRON ALGORITHM}%

The perceptron's hypothesis class of homogenous halfspaces $ \mathcal{H} = \left\{ x \mapsto sign(\langle w, x \rangle) \right\}  $, If $ d \ge 2 $ then $ Ldim(\mathcal{H}) = \infty $.

The perceptron equals to gradient descent for calculating minimization of $ l^{hinge} = \max\left\{ 0, 1 - y_t \langle w, x_t \rangle \right\}$.The subgradient is 
\[
    v_t  = -1_{[y_t \langle w^{(t)}, x_t \rangle \le 0]} y_t x_t
\]

Using preceeding section theorem, we have
\[
    \sum^{T}_{t=1} l^{hinge}(w^{(t)}, z_t) - \sum^{T}_{t=1} l^{hinge}(w, z_t) \le \frac{1}{2\eta} \Arrowvert w \Arrowvert^2_2 + \frac{\eta}{2} \sum^{T}_{t=1} \Arrowvert v_t \Arrowvert^2_2
\]
Let $ M = \sum^{T}_{t=1} l^{0-1}(w^{(t)}, z_t) $, then
\[
    M - \sum^{T}_{t=1} l^{hinge}(w, z_t) \le \frac{1}{2\eta} \Arrowvert w \Arrowvert^2_2 + \frac{\eta}{2} M R^2 = R \Arrowvert w \Arrowvert \sqrt{M}, \quad \eta = \frac{ \Arrowvert w \Arrowvert}{R \sqrt{M}}, R = \max_{t} \Arrowvert x_t \Arrowvert
\]
\[
    M \le \sum^{T}_{t=1} l^{hinge}(w,z_t) + R \Arrowvert w \Arrowvert \sqrt{ \sum^{T}_{t=1} l^{hinge}(w, z_t)} + R^2 \Arrowvert w \Arrowvert^2
\]
If $ \exists w^*, \forall t, y_t \langle w^*, x_t \rangle \ge 1 $, then $ M \le R^2 \Arrowvert w^* \Arrowvert^2 $. (Separability with large margin)

($ x - b\sqrt x - c \le 0 \Rightarrow x \le c + b^2 + b \sqrt c $)

note: there can be cases in which there exists some $ w^* $ that makes zero errors on the sequence but the Perceptron will make many errors, which is a direct consequence of the fact that $ Ldim(\mathcal{H}) = \infty $. We sidestep this impossibility result is assuming that adding assumption that $ \sum^{T}_{t=1} l^{hinge}(w,z_t) $ is note excessively large.


